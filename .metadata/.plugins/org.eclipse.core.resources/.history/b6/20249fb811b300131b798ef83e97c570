#include <opencv2/core/core.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/video/tracking.hpp>
#include <opencv2/nonfree/features2d.hpp>
#include <opencv2/objdetect/objdetect.hpp>
#include <opencv2/legacy/legacy.hpp>
#include <bits/stdc++.h>
#include <vector>
#include <algorithm>
#include "skincolor.h"
#include "findcontour.h"
#include <X11/Xlib.h>
#include <X11/Xutil.h>
#include "GRT.h"
#include "label.h"
#define PI 3.14159265
using namespace cv;
using namespace std;
int main(int argc, const char *argv[])
{


	VideoCapture cap("/home/mac/Documents/PROJECT/Training_Sets/Moon_3/moon_divya (2).mp4");
	noframes=1;
	Mat3b frame;
	vector<Point> coordinate;

	mapskeleton human;

	int options,hands_count=0;
	cout<<"Enter the options "<<endl;
	cout<<"1 Training Mode "<<endl;
	cout<<"2 Recognize Gesture "<<endl;
	cin>>options;
	double dWidth = cap.get(CV_CAP_PROP_FRAME_WIDTH); //get the width of frames of the video
	double dHeight = cap.get(CV_CAP_PROP_FRAME_HEIGHT); //get the height of frames of the video
	Size frameSize(static_cast<int>(dWidth), static_cast<int>(dHeight));
	VideoWriter oVideoWriter ("/home/mac/Documents/PROJECT/Output/moon4_t.avi", CV_FOURCC('P','I','M','1'), 20, frameSize, true); //initialize the VideoWriter object
	VideoWriter oVideoWriter1 ("/home/mac/Documents/PROJECT/Output/moon4_s.avi", CV_FOURCC('P','I','M','1'), 20, frameSize, true); //initialize the VideoWriter object
	Mat trace = Mat::zeros( Size(dWidth,dHeight), CV_8UC3 );
		while(cap.read(frame ) and (options==1 or options==2))
	{
		noframes+=1;
		//if(noframes<5) continue;
		skin = GetSkin(frame);
		cvtColor(skin,skin,CV_RGB2GRAY);
		skin1 = skin> 50;
		blur( skin1, skin1, Size(3,3) );
		char* source_window = "Source";
		src_gray=skin1;
		Mat output;
		Point array[3],dime[3];int sz=0;
		skin1=draw_contour(src_gray,array,sz,dime);
		if(sz and !human.facefixed)
		{
			human.facefixed=true;
			human.face=array[0];
			human.facel=dime[0];
		}
		human.face_map(array,dime,sz,skin1);
		if(sz>1)
		{
			MyCircle(trace,array[0],0);

			imshow("draw",trace);
			oVideoWriter.write(trace);
		}
		Point aux;
		/*
		if(human.facefixed)
			measure_particlefilter(human.faceb.x,human.faceb.y,condensH,skin1,aux);
		if(human.lefthand)
			measure_particlefilter(human.left.x,human.left.y,condensL,skin1,aux);
		if(human.righthand)
			measure_particlefilter(human.right.x,human.right.y,condensR,skin1,aux);
		 */

		//Mat aux=thresh_callback(0,0);
		//drawKeypoints(skin1, keypoints, output);
		skin2=frame;

		blur( skin1, skin1, Size( 5, 5 ) );
		imshow(source_window, skin1);
		oVideoWriter1.write(skin1);
		if(sz>2) hands_count++;
		if(sz>1)
		{VectorDouble sample(2);sample[0] = array[0].x;sample[1] = array[0].y;trainingSample.push_back(sample);}
		waitKey(50);
	}
}
