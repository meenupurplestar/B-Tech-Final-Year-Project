#include <bits/stdc++.h>
#include <vector>
#include "GRT.h"
#include <algorithm>
#include "learn.h"

void learn::setup(){


    //Initialize the training and info variables
    infoText = "";
    trainingClassLabel = 1;
    record = false;
    //The input to the training data will be the [x y] from the mouse, so we set the number of dimensions to 2
    trainingData.setNumDimensions( 2 );
    trainingData.setDatasetName("Gesture_train");
    trainingData.setInfoText("This data contains some Gesture timeseries data");

    //Initialize the DTW classifier
    DTW dtw;

    //Turn on null rejection, this lets the classifier output the predicted class label of 0 when the likelihood of a gesture is low
    dtw.enableNullRejection( true );

    //Set the null rejection coefficient to 3, this controls the thresholds for the automatic null rejection
    //You can increase this value if you find that your real-time gestures are not being recognized
    //If you are getting too many false positives then you should decrease this value
    dtw.setNullRejectionCoeff( 3 );

    //Turn on the automatic data triming, this will remove any sections of none movement from the start and end of the training samples
    dtw.enableTrimTrainingData(true, 0.1, 90);

    //Offset the timeseries data by the first sample, this makes your gestures (more) invariant to the location the gesture is performed
    dtw.setOffsetTimeseriesUsingFirstSample(true);

    //Add the classifier to the pipeline (after we do this, we don't need the DTW classifier anymore)
    //pipeline.setClassifier( dtw );
}

//--------------------------------------------------------------
void learn::update(int mouseX,int mouseY){

    //Grab the current mouse x and y position
    VectorDouble sample(2);
    sample[0] = mouseX;
    sample[1] = mouseY;

    //If we are recording training data, then add the current sample to the training data set
    if( record )
    {
        timeseries.push_back( sample );
    }

    //If the pipeline has been trained, then run the prediction
   // if( pipeline.getTrained() ){
     //   pipeline.predict( sample );
   // }
}
void learn:save()
{

	trainingData.addSample( gestureLabel, trainingSample );

}
void learn::keyPressed(int key){

    infoText = "";

    switch ( key) {
        case 'r':
            record = !record;
            if( !record ){
                trainingData.addSample(trainingClassLabel, timeseries);

                //Clear the timeseries for the next recording
                timeseries.clear();
            }
            break;
        case '[':
            if( trainingClassLabel > 1 )
                trainingClassLabel--;
            break;
        case ']':
            trainingClassLabel++;
            break;
        case 't':
            if( pipeline.train( trainingData ) ){
                infoText = "Pipeline Trained";
            }else infoText = "WARNING: Failed to train pipeline";
            break;
        case 's':
            if( trainingData.saveDatasetToFile("TrainingData.txt") ){
                infoText = "Training data saved to file";
            }else infoText = "WARNING: Failed to save training data to file";
            break;
        case 'l':
            if( trainingData.loadDatasetFromFile("TrainingData.txt") ){
                infoText = "Training data saved to file";
            }else infoText = "WARNING: Failed to load training data from file";
            break;
        case 'c':
            trainingData.clear();
            infoText = "Training data cleared";
            break;
        default:
            break;
    }

}
