#include <opencv2/core/core.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/video/tracking.hpp>
#include <opencv2/nonfree/features2d.hpp>
#include <opencv2/objdetect/objdetect.hpp>
#include <opencv2/legacy/legacy.hpp>
#include <bits/stdc++.h>
#include <vector>
#include <algorithm>
#include "skincolor.h"
#include "findcontour.h"
#include <X11/Xlib.h>
#include <X11/Xutil.h>
#include "label.h"
#define PI 3.14159265
using namespace cv;
using namespace std;
Mat src, src_gray,skin1,drawing,skin,skin2;
long long int noframes;



int edgeThresh = 1;
int lowThreshold=50;
int const max_lowThreshold = 100;
int ratio = 3;
int kernel_size = 3;
char* window_name = "Edge Map";
Mat CannyThreshold(int, void*,Mat src,Mat src_gray)
{
  /// Reduce noise with a kernel 3x3
	Mat dst, detected_edges;

  blur( src_gray, detected_edges, Size(3,3) );

  /// Canny detector
  Canny( detected_edges, detected_edges, lowThreshold, lowThreshold*ratio, kernel_size );

  /// Using Canny's output as a mask, we display our result
  dst = Scalar::all(0);

  src.copyTo( dst, detected_edges);
  imshow( window_name, dst );
  return dst;
 }
int main(int argc, const char *argv[])
{


	VideoCapture cap("/home/mac/Documents/PROJECT/Training_Sets/Mother/mother_kiruthika (1).mp4");
	//VideoCapture cap(0);
	noframes=1;
	Mat3b frame;
	vector<Point> coordinate;

	mapskeleton human;

	int options=1,hands_count=0;
	double dWidth = cap.get(CV_CAP_PROP_FRAME_WIDTH); //get the width of frames of the video
	double dHeight = cap.get(CV_CAP_PROP_FRAME_HEIGHT); //get the height of frames of the video
	Size frameSize(static_cast<int>(dWidth), static_cast<int>(dHeight));
	VideoWriter oVideoWriter ("/home/mac/Documents/PROJECT/Output/moon4_t.avi", CV_FOURCC('P','I','M','1'), 20, frameSize, true); //initialize the VideoWriter object
	VideoWriter oVideoWriter1 ("/home/mac/Documents/PROJECT/Output/moon4_s.avi", CV_FOURCC('P','I','M','1'), 20, frameSize, true); //initialize the VideoWriter object
	Mat trace = Mat::zeros( Size(dWidth,dHeight), CV_8UC3 );
	Mat prev,current,next,d1,d2,results;
	current=next=prev=Mat::zeros( Size(dWidth,dHeight), CV_8UC3 );

	while(cap.read(frame ) and (options==1 or options==2))
	{
		noframes+=1;

		skin = GetSkin(frame);
		cvtColor(skin,skin,CV_RGB2GRAY);
		skin1 = skin> 50;
		blur( skin1, skin1, Size(3,3) );
		char* source_window = "Source";
		src_gray=skin1;
		Mat output;
		Point array[3],dime[3];int sz=0;
		skin1=draw_contour(src_gray,array,sz,dime,frame);
		if(sz and !human.facefixed)
		{
			human.facefixed=true;
			human.face=array[0];
			human.facel=dime[0];
		}
		human.face_map(array,dime,sz,skin1);
		Point aux;
		Mat skin3,skin1_gray;
		cvtColor(skin1,skin1_gray,CV_BGR2GRAY);
		skin2=frame;
	 	//cvtColor(skin1,skin3,CV_RGB2GRAY);
		skin1_gray=CannyThreshold(0, 0,skin1,skin1_gray);
		if(noframes<3)
		{
			if(noframes==1)
					prev=skin1_gray;
			if(noframes==2)
					current=skin1_gray;
		}
		else
		{
			next=skin1_gray;
			absdiff(prev, next, d1);
			absdiff(current, next, d2);
			bitwise_and(d1, d2, results);
			threshold(results, results, 70, 255, CV_THRESH_BINARY);
			prev=current;
			current=next;
			imshow("detect",results);

		}

		blur( skin1, skin1, Size( 5, 5 ) );
		//current=skin1;
		imshow(source_window, skin1);
		oVideoWriter1.write(skin1);
		waitKey(50);
	}
	return 0;
}
